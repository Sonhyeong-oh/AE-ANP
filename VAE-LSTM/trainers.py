import numpy as np
import matplotlib.pylab as plt
from matplotlib.pyplot import savefig
import tensorflow as tf
from tqdm import tqdm
import os 

class ModelTrainer:
    def __init__(self, model, train_data_loader, val_data_loader, config):
        self.model = model
        self.train_data_loader = train_data_loader
        self.val_data_loader = val_data_loader
        self.config = config
        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.config['learning_rate'])
        self.train_loss_tracker = tf.keras.metrics.Mean(name='train_loss')
        self.val_loss_tracker = tf.keras.metrics.Mean(name='val_loss')
        
        # ìµœì ì˜ Validation Lossë¥¼ ì¶”ì í•˜ê¸° ìœ„í•œ ë³€ìˆ˜ ì´ˆê¸°í™”
        self.best_val_loss = float('inf')
        
        # [ì¶”ê°€] Early Stoppingì„ ìœ„í•œ ë³€ìˆ˜
        self.patience = 5  # ê°œì„ ì´ ì—†ì–´ë„ ê¸°ë‹¤ë ¤ì¤„ íšŸìˆ˜
        self.wait = 0      # í˜„ì¬ ê°œì„ ë˜ì§€ ì•Šì€ ì—°ì† íšŸìˆ˜ ì¹´ìš´í„°

        # ê·¸ë˜í”„ ì‘ì„±ì„ ìœ„í•´ ì—í¬í¬ë³„ Lossë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
        self.train_loss_history = []
        self.val_loss_history = []

    def train(self):
        for epoch in range(self.config['num_epochs']):
            print(f"Epoch {epoch + 1}/{self.config['num_epochs']}")
            self.train_epoch()
            self.validate_epoch()
            
            # í˜„ì¬ ì—í¬í¬ì˜ Loss ê°’ ê°€ì ¸ì˜¤ê¸°
            current_train_loss = self.train_loss_tracker.result().numpy()
            current_val_loss = self.val_loss_tracker.result().numpy()

            print(f"Train Loss: {current_train_loss:.4f}, "
                  f"Validation Loss: {current_val_loss:.4f}")

            # [ìˆ˜ì •] Best Model ì €ì¥ ë° Early Stopping ë¡œì§ ì ìš©
            if current_val_loss < self.best_val_loss:
                print(f"âœ… Validation Loss improved from {self.best_val_loss:.4f} to {current_val_loss:.4f}. Saving model...")
                self.best_val_loss = current_val_loss
                
                # Validation Lossê°€ ê°œì„ ë˜ì—ˆìœ¼ë¯€ë¡œ ê¸°ë‹¤ë¦¼ ì¹´ìš´í„° ì´ˆê¸°í™”
                self.wait = 0 
                
                # ì €ì¥ ê²½ë¡œ ì„¤ì •
                save_path = os.path.join(self.config['result_dir'], 'best_model_vl.weights.h5')
                self.model.save_weights(save_path)
            else:
                # Validation Lossê°€ ê°œì„ ë˜ì§€ ì•ŠìŒ
                self.wait += 1
                print(f"âš ï¸ Validation Loss did not improve. (Wait: {self.wait}/{self.patience})")

            # ê·¸ë˜í”„ë¥¼ ìœ„í•´ ê¸°ë¡ ì €ì¥
            self.train_loss_history.append(current_train_loss)
            self.val_loss_history.append(current_val_loss)

            # self.plot_reconstructed_signal(epoch)
            # self.plot_train_and_val_loss(epoch)
            
            self.train_loss_tracker.reset_state()
            self.val_loss_tracker.reset_state()

            # [ì¶”ê°€] Early Stopping ì²´í¬
            if self.wait >= self.patience:
                print(f"\nğŸ›‘ Early Stopping Triggered! Validation loss did not improve for {self.patience} consecutive epochs.")
                print(f"Training stopped at Epoch {epoch + 1}.")
                break

    def train_epoch(self):
        total_batches = (len(self.train_data_loader.sequences) + self.config['batch_size'] - 1) // self.config['batch_size']
        
        with tqdm(self.train_data_loader.get_dataset(), desc="Training", total=total_batches) as pbar:
            for batch in pbar:
                self.train_step(batch)
                current_loss = self.train_loss_tracker.result().numpy()
                pbar.set_postfix({'loss': f'{current_loss:.4f}'})

    def train_step(self, batch):
        sensor_signal, image_signal, _, _ = batch = batch
        with tf.GradientTape() as tape:
            decoded_signal = self.model([sensor_signal, image_signal])
            loss, _, _ = self.model.define_loss(sensor_signal, decoded_signal)
        
        grads = tape.gradient(loss, self.model.trainable_variables)
        self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))
        self.train_loss_tracker.update_state(loss)

    def validate_epoch(self):
        total_batches = (len(self.val_data_loader.sequences) + self.config['batch_size'] - 1) // self.config['batch_size']
        
        with tqdm(self.val_data_loader.get_dataset(), desc="Validating", total=total_batches) as pbar:
            for batch in pbar:
                self.val_step(batch)
                current_val_loss = self.val_loss_tracker.result().numpy()
                pbar.set_postfix({'val_loss': f'{current_val_loss:.4f}'})

    def val_step(self, batch):
        sensor_signal, image_signal, _, _ = batch = batch
        decoded_signal = self.model([sensor_signal, image_signal])
        loss, _, _ = self.model.define_loss(sensor_signal, decoded_signal)
        self.val_loss_tracker.update_state(loss)
    
    # def plot_reconstructed_signal(self, epoch):
    #     # ë°ì´í„°ì…‹ì—ì„œ ë°°ì¹˜ í•˜ë‚˜ ê°€ì ¸ì˜¤ê¸° (iter ì¬ì„±ì„± ë°©ì§€ë¥¼ ìœ„í•´ ì£¼ì˜ í•„ìš”í•˜ì§€ë§Œ, ì—¬ê¸°ì„  ë‹¨ìˆœí™”)
    #     # tf.data.Datasetì€ ë°˜ë³µ ê°€ëŠ¥í•˜ë¯€ë¡œ ë§¤ë²ˆ ìƒˆë¡œ í˜¸ì¶œë¨
    #     try:
    #         batch = next(iter(self.val_data_loader.get_dataset()))
    #     except StopIteration:
    #         return 

    #     sensor_signal, image_signal, _, _ = batch

    #     decoded_signal = self.model([sensor_signal, image_signal])
    #     n_signals = min(10, self.config['batch_size'])
        
    #     for j in range(sensor_signal.shape[-1]):
    #         fig, axs = plt.subplots(2, 5, figsize=(15, 6), edgecolor='k')
    #         fig.subplots_adjust(hspace=.4, wspace=.4)
    #         axs = axs.ravel()
    #         for i in range(n_signals):
    #             # zero-padding ì œê±° í›„ plotting (ì›ë³¸ ì½”ë“œ ë¡œì§ ìœ ì§€)
    #             input_len = np.trim_zeros(sensor_signal[i, :, j], 'b').shape[0]
    #             # ë°ì´í„°ê°€ ì „ë¶€ 0ì¸ ê²½ìš° shapeì´ 0ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì˜ˆì™¸ ì²˜ë¦¬ í˜¹ì€ ì›ë³¸ ê¸¸ì´ ì‚¬ìš© ê¶Œì¥
    #             if input_len == 0: input_len = sensor_signal.shape[1]

    #             axs[i].plot(sensor_signal[i, :input_len, j])
    #             axs[i].plot(decoded_signal[i, :input_len, j])
    #             axs[i].grid(True)
    #             axs[i].set_title(f'Sample {i}')
    #             if i == 0:
    #                 axs[i].legend(('Original', 'Reconstructed'))
            
    #         plt.suptitle(f'Epoch {epoch + 1} - Channel {j} Reconstruction')
    #         save_path = os.path.join(self.config['result_dir'], f'reconstruction_epoch_{epoch + 1}_ch{j}.pdf')
    #         # savefig(save_path)
    #         fig.clf()
    #         plt.close()

    # def plot_train_and_val_loss(self, epoch):
    #     plt.figure(figsize=(10, 6))
    #     plt.plot(self.train_loss_history, label='Train Loss')
    #     plt.plot(self.val_loss_history, label='Validation Loss')
    #     plt.title('Training and Validation Loss')
    #     plt.xlabel('Epoch')
    #     plt.ylabel('Loss')
    #     plt.legend()
    #     plt.grid(True)
        
    #     save_path = os.path.join(self.config['result_dir'], f'loss_graph_epoch_{epoch + 1}.pdf')
    #     # savefig(save_path)
    #     plt.close()